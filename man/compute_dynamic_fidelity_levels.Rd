% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bo_calibrate.R
\name{compute_dynamic_fidelity_levels}
\alias{compute_dynamic_fidelity_levels}
\title{Select fidelity using staged multi-fidelity strategy}
\usage{
compute_dynamic_fidelity_levels(
  iter,
  budget,
  base_levels,
  budget_used = 0,
  budget_tolerance = 1.2,
  batch_size = 1
)
}
\arguments{
\item{iter}{current BO iteration number (not evaluation count)}

\item{budget}{total evaluation budget}

\item{base_levels}{named vector of base fidelity levels (e.g., c(low=200, med=1000, high=5000))}

\item{budget_used}{cumulative computational budget consumed (sum of n_rep)}

\item{budget_tolerance}{maximum allowed budget overhead (default 1.2 = 20% over)}

\item{batch_size}{batch size q for computing iteration phases}

\item{prob_feasible}{probability of constraint satisfaction
Compute dynamic fidelity levels based on iteration progress

Implements MCEM-inspired continuous escalation by scaling fidelity levels
as the optimization progresses. Balances exploration (low cost) vs refinement
(high precision) with budget safeguards.}
}
\value{
named numeric vector of adjusted fidelity levels
}
\description{
Implements the staged approach described in manuscript Section 2.4:
- Iterations 1-30: uniform low fidelity for exploration
- Iterations 31-100: adaptive selection based on feasibility and CV
- Iterations 101+: high fidelity near optimum and boundaries
}
\details{
Scaling strategy based on empirical patterns from BOHB and materials discovery:
\itemize{
  \item \strong{Early phase} (iter < 20% budget): Base levels - exploration phase
  \item \strong{Middle phase} (20% <= iter < 60%): 1.5x scaling - focused search
  \item \strong{Late phase} (iter >= 60%): High-fidelity levels increase to 2x/3x - refinement
}

Moderate scaling for high fidelity: 5000 -> 10000 -> 15000 (user feedback)

Budget safeguard: Caps scaling if theoretical budget would exceed tolerance.
}
\references{
Falkner et al. (2018). BOHB: Robust and Efficient Hyperparameter Optimization. ICML.
Wu & Frazier (2019). Practical Multi-fidelity Bayesian Optimization. UAI.
}
\keyword{internal}
